{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDYej9StY0Xx",
        "outputId": "a5e5d1d5-58a4-4ac4-d68d-6dce0f3ac19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "jasqIKXgaVUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the libraries for Mask R-CNN\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader \n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "metadata": {
        "id": "e8HNLve9aPpT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask1 = cv2.imread(r\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/masks/CHNCXR_0057_0_mask.png\")\n",
        "mask2 = cv2.cvtColor(mask1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "contours, hierarchy = cv2.findContours(mask2, cv2.RETR_EXTERNAL,\n",
        "                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
        "cv2.drawContours(mask1, contours, -1, (0,255,0), 15)\n",
        "plt.imshow(mask1, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "q6SQpUsrpKXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e3621dee-1744-4980-e5cc-cd3909389c31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc0f3e6c250>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bboxes(mask):\n",
        "    \"\"\" Pinpoint the coordinates of the masks. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    mask : numpy array\n",
        "        Mask images.\n",
        "        \n",
        "    Returns\n",
        "    ----------\n",
        "    bboxes : list\n",
        "        Coordinates of the bboxes.    \n",
        "    \"\"\"\n",
        "\n",
        "    # Find different mask areas.\n",
        "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    \n",
        "    bboxes = []\n",
        "    \n",
        "    for contour in contours:\n",
        "       # Get start and end locations of the bbox.\n",
        "       start = np.min(contour, axis=0)\n",
        "       end = np.max(contour, axis=0)\n",
        "       \n",
        "       # Concantenate the two array to obtain [x1, y1, x2, y2]\n",
        "       coors = np.concatenate((start.tolist()[0], end.tolist()[0]))\n",
        "       \n",
        "        # Convert coordinates to COCO format.\n",
        "       coors[2] = coors[2] - coors[0]\n",
        "       coors[3] = coors[3] - coors[1]\n",
        "        \n",
        "       bboxes.append(coors)\n",
        "        \n",
        "    return bboxes\n",
        "\n",
        "\n",
        "def get_segmentations(mask):\n",
        "       \n",
        "    contours, hierarchy = cv2.findContours((mask).astype(np.uint8), cv2.RETR_EXTERNAL,\n",
        "                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segmentation = []\n",
        "\n",
        "    for contour in contours:        \n",
        "        contour = contour.flatten()\n",
        "        # segmentation.append(contour)\n",
        "        if len(contour) > 4:\n",
        "            segmentation.append(contour.astype(float))\n",
        "    \n",
        "    return segmentation\n",
        "\n",
        "\n",
        "\n",
        "def create_COCO_JSON(path, files):\n",
        "    \"\"\"Creates annotations from masks in COCO format.  \n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        Base path of the masks.\n",
        "    files : str\n",
        "        Mask image names.\n",
        "        \n",
        "    Returns\n",
        "    ---------\n",
        "    new_data : dict\n",
        "        Annoation content of the all masks in COCO format.\n",
        "    \"\"\"\n",
        "  \n",
        "    new_data = {\"images\": [], \n",
        "                \"categories\": [{\"id\": 0,\n",
        "                                \"name\": \"chest\",\n",
        "                                \"color\": \"#0ed41a\"}], \n",
        "                \"annotations\": []}\n",
        "    im_id = 0\n",
        "    anno_id = 0\n",
        "\n",
        "    for file in files:\n",
        "        mask = cv2.imread(os.path.join(path, file))\n",
        "        if file[0] == 'C':\n",
        "          file = file.split(\"_mask\")[0]+\".png\"\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        h, w = mask.shape\n",
        "\n",
        "        tmp_im = {\"id\": im_id,\n",
        "                  \"file_name\": file,\n",
        "                  \"height\": h,\n",
        "                  \"width\": w,\n",
        "                 }\n",
        "\n",
        "        segmentations = get_segmentations(mask)\n",
        "        bboxes = get_bboxes(mask)\n",
        "        \n",
        "\n",
        "        for index in range(len(segmentations)):\n",
        "          segmentation = segmentations[index].tolist()\n",
        "          bbox= bboxes[index].tolist()\n",
        "          tmp_anno = {\"id\": anno_id, \n",
        "                      \"image_id\": im_id, \n",
        "                      \"category_id\": 0, \n",
        "                      \"bbox\": bbox,\n",
        "                      \"segmentation\": [segmentation],\n",
        "                      \"iscrowd\": False,\n",
        "                      \"area\": (bbox[2]-bbox[0])*(bbox[3]-bbox[1])\n",
        "                         }\n",
        "          \n",
        "        anno_id+= 1\n",
        "\n",
        "        im_id+= 1\n",
        "\n",
        "        new_data[\"images\"].append(tmp_im)\n",
        "        new_data[\"annotations\"].append(tmp_anno)\n",
        "        \n",
        "    return new_data\n",
        "\n",
        "\n",
        "def save_JSON(data, file_name, output_path):    \n",
        "    file_name += '.json'   \n",
        "    full_path = os.path.join(output_path, file_name)\n",
        "    \n",
        "    try:\n",
        "        with open(full_path, 'w') as f:\n",
        "            json.dump(data, f)\n",
        "        print(\"JSON created.\")\n",
        "    except IOError as error:\n",
        "        print(error)\n",
        "\n",
        "\n",
        "mask = \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/masks\"\n",
        "name_train = \"chest_train\"\n",
        "name_val = \"chest_val\"\n",
        "output = \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation\"\n",
        "\n",
        "\n",
        "\n",
        "files = os.listdir(mask)\n",
        "train = files[:640]\n",
        "validation = files [640:]\n",
        "data_train = create_COCO_JSON(mask, train)\n",
        "data_val = create_COCO_JSON(mask, validation)\n",
        "\n",
        "\n",
        "save_JSON(data_train, name_train, output)\n",
        "save_JSON(data_val, name_val, output)\n"
      ],
      "metadata": {
        "id": "oIACWuE0Y4JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "register_coco_instances(\"train\", {}, \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/chest_train.json\", \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png\")\n",
        "register_coco_instances(\"val\", {}, \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/chest_val.json\", \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png\")"
      ],
      "metadata": {
        "id": "zyz6yDb7bgv4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure and train the model.\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 0\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml\")\n",
        "#cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_C4_3x/137849458/model_final_280758.pkl\"  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []   \n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "#cfg.INPUT.MIN_SIZE_TRAIN = (800,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 500\n",
        "cfg.OUTPUT_DIR = \"gdrive/MyDrive/Mask_R-CNN_outputs/output/\"\n",
        "cfg.MODEL.DEVICE='cpu'\n",
        "\n",
        "#os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "#trainer.train()\n"
      ],
      "metadata": {
        "id": "Z20u7RDQbAWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79dcb13b-caaf-46ec-f31b-864bfa222535"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[01/06 10:30:07 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/06 10:30:07 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/06 10:30:07 d2.data.datasets.coco]: \u001b[0mLoaded 640 images in COCO format from /content/gdrive/MyDrive/Kaggle/Lung Segmentation/chest_train.json\n",
            "\u001b[32m[01/06 10:30:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 640 images left.\n",
            "\u001b[32m[01/06 10:30:07 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|   chest    | 640          |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[01/06 10:30:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=500, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[01/06 10:30:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[01/06 10:30:07 d2.data.common]: \u001b[0mSerializing 640 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/06 10:30:07 d2.data.common]: \u001b[0mSerialized dataset takes 21.61 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "IG9YtszcbwRD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = COCOEvaluator(\"val\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"val\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "metadata": {
        "id": "tOyXcaF_FAcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onlyfiles = [f for f in listdir('/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png') if isfile(join('/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png', f))]"
      ],
      "metadata": {
        "id": "MpS6hXSds2BV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_path = \"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/chest_val.json\"\n",
        "\n",
        "with open(json_file_path, 'r') as j:\n",
        "  contents = json.loads(j.read())"
      ],
      "metadata": {
        "id": "jSdr20MGT6l9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = [item[\"file_name\"] for item in contents[\"images\"]]"
      ],
      "metadata": {
        "id": "o5o2se7iZZlJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_images = []\n",
        "file_images = []\n",
        "\n",
        "for images in contents[\"images\"]:\n",
        "  image = images[\"file_name\"]  \n",
        "  file_images.append(image)\n",
        "  \n",
        "  if image[0] == 'C':\n",
        "    x=image.split(\".\")\n",
        "    mask = \"_mask.\"\n",
        "    image = x[0]+mask+x[1]\n",
        "\n",
        "  mask_images.append(image)"
      ],
      "metadata": {
        "id": "4dmT1_Mb4HSZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    \n",
        "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)"
      ],
      "metadata": {
        "id": "znBvXRFRQFhC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (7, 7))\n",
        "\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "\n",
        "sum = 0\n",
        "index = 0\n",
        "\n",
        "for i in range(len(mask_images)):\n",
        "  img = cv2.imread(os.path.join(\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png\", file_images[i]))\n",
        "  predict = predictor(img)\n",
        "\n",
        "  if len(predict[\"instances\"]) == 0:\n",
        "    dice_score=0\n",
        "    print(\"Dice score of \"+ file_images[i] + \" = \" + str(dice_score))\n",
        "    index = index - 1\n",
        "  else:\n",
        "    mask = cv2.imread(os.path.join(\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/masks\", mask_images[i]))\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)   \n",
        "    mask[mask==255] = 1\n",
        "\n",
        "    for instance in predict[\"instances\"].pred_masks:\n",
        "      mask_pred = instance.cpu().detach().numpy().astype('uint8')\n",
        "      dice_score = dice_coef(mask, mask_pred)\n",
        "      sum = sum + dice_score\n",
        "      index = index + 1\n",
        "  \n",
        "      print(\"Dice score of \"+ file_images[i] + \" = \" + str(dice_score))\n",
        "\n",
        "result = sum / index\n",
        "print(result)  "
      ],
      "metadata": {
        "id": "PJgwc18MIhSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_times = []\n",
        "\n",
        "for image in file_names:\n",
        "  start = time.time()\n",
        "  test_image = cv2.imread(os.path.join(\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png\", image))\n",
        "  outputs = predictor(test_image)\n",
        "  end = time.time()\n",
        "  pred_times.append(round(end - start, 3))\n",
        "  print(str(round(end - start, 3)) + \" second.\")"
      ],
      "metadata": {
        "id": "plBoYS0qH_8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i in pred_times:\n",
        "  sum = sum + i\n",
        "print(sum/64)"
      ],
      "metadata": {
        "id": "WNm0xywxg1AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread(\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/CXR_png/\"+file_names[10])\n",
        "outputs = predictor(test_image)"
      ],
      "metadata": {
        "id": "fMKbO62n67fM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = outputs[\"instances\"].pred_masks[0].cpu().detach().numpy().astype('int16')\n",
        "y_true = cv2.imread(\"/content/gdrive/MyDrive/Kaggle/Lung Segmentation/masks/CHNCXR_0004_0_mask.png\")\n",
        "y_true = y_true[:,:,0]"
      ],
      "metadata": {
        "id": "DGwDrjNMotY7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = Visualizer(test_image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "KmY-5nb0hfMU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}