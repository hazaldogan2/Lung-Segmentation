{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import all the libraries for SegNet\nimport numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nimport sys\nimport cv2\nimport time\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\nfrom IPython.display import clear_output\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.optimizers import SGD","metadata":{"execution":{"iopub.status.busy":"2022-01-06T10:05:00.259869Z","iopub.execute_input":"2022-01-06T10:05:00.260189Z","iopub.status.idle":"2022-01-06T10:05:06.152075Z","shell.execute_reply.started":"2022-01-06T10:05:00.260108Z","shell.execute_reply":"2022-01-06T10:05:06.151304Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"image_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/data/Lung Segmentation/masks/\")\n\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\n\nmask = [fName.split(\".png\")[0] for fName in mask] # name of the mask or segment\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask] # name of the image file","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:25:23.521394Z","iopub.execute_input":"2022-01-06T08:25:23.521810Z","iopub.status.idle":"2022-01-06T08:25:24.098703Z","shell.execute_reply.started":"2022-01-06T08:25:23.521776Z","shell.execute_reply":"2022-01-06T08:25:24.097958Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\",len(check))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:25:24.124871Z","iopub.execute_input":"2022-01-06T08:25:24.125588Z","iopub.status.idle":"2022-01-06T08:25:24.131321Z","shell.execute_reply.started":"2022-01-06T08:25:24.125545Z","shell.execute_reply":"2022-01-06T08:25:24.130222Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Get data\ntesting_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\ndef getData(X_shape, flag = \"test\"):\n    im_array = []\n    mask_array = []\n    \n    if flag == \"test\":\n        for i in tqdm(testing_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]\n            \n            im_array.append(im)\n            mask_array.append(mask)\n        \n        return im_array,mask_array\n    \n    if flag == \"train\":\n        for i in tqdm(training_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\")),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i+\".png\")),(X_shape,X_shape))[:,:,0]\n\n            im_array.append(im)\n            mask_array.append(mask)\n\n        return im_array,mask_array","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:25:25.411285Z","iopub.execute_input":"2022-01-06T08:25:25.411909Z","iopub.status.idle":"2022-01-06T08:25:25.422338Z","shell.execute_reply.started":"2022-01-06T08:25:25.411861Z","shell.execute_reply":"2022-01-06T08:25:25.421248Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Perform sanity check\ndef plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i])\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1])\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2])\n        \n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:25:27.838966Z","iopub.execute_input":"2022-01-06T08:25:27.839366Z","iopub.status.idle":"2022-01-06T08:25:27.845518Z","shell.execute_reply.started":"2022-01-06T08:25:27.839334Z","shell.execute_reply":"2022-01-06T08:25:27.844900Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load training and testing data\ndim = 256*2\nX_train,y_train = getData(dim,flag=\"train\")\nX_test, y_test = getData(dim)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:25:32.851014Z","iopub.execute_input":"2022-01-06T08:25:32.851289Z","iopub.status.idle":"2022-01-06T08:28:32.288018Z","shell.execute_reply.started":"2022-01-06T08:25:32.851260Z","shell.execute_reply":"2022-01-06T08:28:32.287061Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"training set\")\nplotMask(X_train,y_train)\n\nprint(\"testing set\")\nplotMask(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T14:16:04.244464Z","iopub.execute_input":"2022-01-05T14:16:04.245170Z","iopub.status.idle":"2022-01-05T14:16:06.909827Z","shell.execute_reply.started":"2022-01-05T14:16:04.245126Z","shell.execute_reply":"2022-01-05T14:16:06.908944Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\ny_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\nX_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\ny_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\nassert X_train.shape == y_train.shape\nassert X_test.shape == y_test.shape\nimages = np.concatenate((X_train,X_test),axis=0)\nmask  = np.concatenate((y_train,y_test),axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:21.544783Z","iopub.execute_input":"2022-01-06T08:29:21.545088Z","iopub.status.idle":"2022-01-06T08:29:21.923863Z","shell.execute_reply.started":"2022-01-06T08:29:21.545056Z","shell.execute_reply":"2022-01-06T08:29:21.922717Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth = 100):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + smooth)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:22.719899Z","iopub.execute_input":"2022-01-06T08:29:22.720179Z","iopub.status.idle":"2022-01-06T08:29:22.725396Z","shell.execute_reply.started":"2022-01-06T08:29:22.720147Z","shell.execute_reply":"2022-01-06T08:29:22.724307Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def precision(y_true, y_pred):\n    '''Calculates the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    '''\n    true_positives = keras.sum(keras.round(keras.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = keras.sum(keras.round(keras.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + keras.epsilon())\n    return precision","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:28.011298Z","iopub.execute_input":"2022-01-06T08:29:28.011614Z","iopub.status.idle":"2022-01-06T08:29:28.035376Z","shell.execute_reply.started":"2022-01-06T08:29:28.011580Z","shell.execute_reply":"2022-01-06T08:29:28.034297Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_true, y_pred):\n    '''Calculates the mean accuracy rate across all predictions for binary\n    classification problems.\n    '''\n    return keras.mean(keras.equal(y_true, keras.round(y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:28.981154Z","iopub.execute_input":"2022-01-06T08:29:28.981995Z","iopub.status.idle":"2022-01-06T08:29:28.986226Z","shell.execute_reply.started":"2022-01-06T08:29:28.981945Z","shell.execute_reply":"2022-01-06T08:29:28.985473Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:29.820574Z","iopub.execute_input":"2022-01-06T08:29:29.820880Z","iopub.status.idle":"2022-01-06T08:29:29.824775Z","shell.execute_reply.started":"2022-01-06T08:29:29.820822Z","shell.execute_reply":"2022-01-06T08:29:29.824173Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#SegNet Model\ndef segnet(input_size=(512,512,1)):\n    img_input = Input(input_size)\n    # Encoding layer   \n    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n    x = BatchNormalization(name='bn1')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n    x = BatchNormalization(name='bn5')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n    x = BatchNormalization(name='bn6')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n    x = BatchNormalization(name='bn7')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n    x = BatchNormalization(name='bn8')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n    x = BatchNormalization(name='bn9')(x)\n    \n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n    x = BatchNormalization(name='bn10')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n    x = BatchNormalization(name='bn11')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n    x = BatchNormalization(name='bn12')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n    x = BatchNormalization(name='bn13')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Dense(1024, activation = 'relu', name='fc1')(x)\n    x = Dense(1024, activation = 'relu', name='fc2')(x)\n    \n    # Decoding Layer \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n    x = BatchNormalization(name='bn14')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n    x = BatchNormalization(name='bn15')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n    x = BatchNormalization(name='bn16')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n    x = BatchNormalization(name='bn17')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n    x = BatchNormalization(name='bn18')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n    x = BatchNormalization(name='bn19')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n    x = BatchNormalization(name='bn20')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n    x = BatchNormalization(name='bn21')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n    x = BatchNormalization(name='bn22')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n    x = BatchNormalization(name='bn23')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n    x = BatchNormalization(name='bn24')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n    x = BatchNormalization(name='bn25')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n    x = BatchNormalization(name='bn26')(x)\n    x = Activation('sigmoid')(x)\n    pred = Reshape((512, 512, 1))(x)\n    outputs = BatchNormalization()(x)\n    \n    return Model(inputs=[img_input], outputs=[outputs])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:31.277578Z","iopub.execute_input":"2022-01-06T08:29:31.278052Z","iopub.status.idle":"2022-01-06T08:29:31.303941Z","shell.execute_reply.started":"2022-01-06T08:29:31.278012Z","shell.execute_reply":"2022-01-06T08:29:31.302732Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = segnet(input_size=(512,512,1))\n\nmodel.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n              , metrics=[dice_coef])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:33.040848Z","iopub.execute_input":"2022-01-06T08:29:33.041763Z","iopub.status.idle":"2022-01-06T08:29:34.000119Z","shell.execute_reply.started":"2022-01-06T08:29:33.041717Z","shell.execute_reply":"2022-01-06T08:29:33.999222Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"weight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15)\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:29:39.740119Z","iopub.execute_input":"2022-01-06T08:29:39.740388Z","iopub.status.idle":"2022-01-06T08:29:39.746641Z","shell.execute_reply.started":"2022-01-06T08:29:39.740360Z","shell.execute_reply":"2022-01-06T08:29:39.745858Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split((images-127.0)/127.0, (mask>127).astype(np.float32), \n                                                  test_size = 0.2,random_state = 2018)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T08:30:36.493069Z","iopub.execute_input":"2022-01-06T08:30:36.493481Z","iopub.status.idle":"2022-01-06T08:30:38.538309Z","shell.execute_reply.started":"2022-01-06T08:30:36.493449Z","shell.execute_reply":"2022-01-06T08:30:38.537623Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit(x = x_train,\n                         y = y_train,\n                         batch_size = 4,\n                         epochs = 16,\n                         validation_data =(x_val,y_val))\n\nmodel.save(\"SegNet_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-05T13:29:52.547934Z","iopub.execute_input":"2022-01-05T13:29:52.548470Z","iopub.status.idle":"2022-01-05T13:45:36.084012Z","shell.execute_reply.started":"2022-01-05T13:29:52.548430Z","shell.execute_reply":"2022-01-05T13:45:36.083271Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"pred_candidates = np.random.randint(1,x_val.shape[0],10)\npreds = model.predict(x_val)\n\n\nplt.figure(figsize=(20,10))\n\nfor i in range(0,9,3):\n    plt.subplot(3,3,i+1)\n    \n    plt.imshow(np.squeeze(x_val[pred_candidates[i]]), cmap=\"gray\")\n    plt.xlabel(\"Base Image\")\n    \n    plt.subplot(3,3,i+2)\n    plt.imshow(np.squeeze(y_val[pred_candidates[i]]), cmap=\"gray\")\n    plt.xlabel(\"Mask\")\n    \n    plt.subplot(3,3,i+3)\n    plt.imshow(np.squeeze(preds[pred_candidates[i]]), cmap=\"gray\")\n    plt.xlabel(\"Pridiction\")","metadata":{},"execution_count":null,"outputs":[]}]}